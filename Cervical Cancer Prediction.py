# -*- coding: utf-8 -*-
"""Danish2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FAl0OdMTR0AJTXi6JiCayosiafW9_iT1
"""

from google.colab import drive
drive.mount('/content/drive')



# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

from PIL import Image
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

base_dir = "/content/drive/MyDrive/archive"
categories = ["im_Dyskeratotic", "im_Koilocytotic", "im_Metaplastic",
              "im_Parabasal", "im_Superficial-Intermediate"]

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")

image_counts = {}

for category in categories:
    category_path = os.path.join(base_dir, category, category, "CROPPED")
    image_counts[category] = len([f for f in os.listdir(category_path) if f.endswith(('.bmp', '.jpg', '.png'))])

print(image_counts)

plt.figure(figsize=(10, 6))
sns.barplot(x=list(image_counts.keys()), y=list(image_counts.values()), palette='viridis')
plt.title('Count of Images in Each Category')
plt.xlabel('Categories')
plt.ylabel('Number of Images')
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(8, 8))
plt.pie(image_counts.values(), labels=image_counts.keys(), autopct='%1.1f%%', startangle=140)
plt.title('Distribution of Images by Category')
plt.axis('equal')
plt.show()

import cv2

def display_images_from_folders(base_dir, categories, num_images=5):
    plt.figure(figsize=(15, 10))

    for i, category in enumerate(categories):
        category_path = os.path.join(base_dir, category, category, "CROPPED")
        image_files = [f for f in os.listdir(category_path) if f.endswith(('.bmp', '.jpg', '.png'))]

        for j, image_file in enumerate(image_files[:num_images]):

            img_path = os.path.join(category_path, image_file)
            image = cv2.imread(img_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB

            plt.subplot(len(categories), num_images, i * num_images + j + 1)
            plt.imshow(image)
            plt.axis('off')
            plt.title(f"{category}")

    plt.tight_layout()
    plt.show()

display_images_from_folders(base_dir, categories, num_images=5)

def create_image_paths_dataframe(base_dir, categories):
    data = []

    for category in categories:
        category_path = os.path.join(base_dir, category, category, "CROPPED")

        image_files = [f for f in os.listdir(category_path) if f.endswith(('.bmp', '.jpg', '.png'))]

        for image_file in image_files:
            img_path = os.path.join(category_path, image_file)
            data.append({'image_path': img_path, 'label': category})

    df_image_paths = pd.DataFrame(data)

    return df_image_paths

df_image_paths = create_image_paths_dataframe(base_dir, categories)

df_image_paths.head()

df_image_paths.tail()

df_image_paths['label'].unique()

df_image_paths['label'].value_counts()

from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(df_image_paths[['image_path']], df_image_paths['label'])

df_resampled = pd.DataFrame(X_resampled, columns=['image_path'])
df_resampled['label'] = y_resampled

print("\nClass distribution after oversampling:")
print(df_resampled['label'].value_counts())

import time
import shutil
import pathlib
import itertools
from PIL import Image

import cv2
import seaborn as sns
sns.set_style('darkgrid')
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam, Adamax
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization
from tensorflow.keras import regularizers

import warnings
warnings.filterwarnings("ignore")

print ('check')

df_resampled.info()

train_df_new, temp_df_new = train_test_split(
    df_resampled,
    train_size=0.8,
    shuffle=True,
    random_state=42,
    stratify=df_resampled['label']
)

valid_df_new, test_df_new = train_test_split(
    temp_df_new,
    test_size=0.5,
    shuffle=True,
    random_state=42,
    stratify=temp_df_new['label']
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

batch_size = 16
img_size = (224, 224)
channels = 3
img_shape = (img_size[0], img_size[1], channels)

tr_gen = ImageDataGenerator(rescale=1./255)
ts_gen = ImageDataGenerator(rescale=1./255)

train_gen_new = tr_gen.flow_from_dataframe(
    train_df_new,
    x_col='image_path',
    y_col='label',
    target_size=img_size,
    class_mode='sparse',
    color_mode='rgb',
    shuffle=True,
    batch_size=batch_size
)

valid_gen_new = ts_gen.flow_from_dataframe(
    valid_df_new,
    x_col='image_path',
    y_col='label',
    target_size=img_size,
    class_mode='sparse',
    color_mode='rgb',
    shuffle=True,
    batch_size=batch_size
)

test_gen_new = ts_gen.flow_from_dataframe(
    test_df_new,
    x_col='image_path',
    y_col='label',
    target_size=img_size,
    class_mode='sparse',
    color_mode='rgb',
    shuffle=False,
    batch_size=batch_size
)

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping

physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    print("Using GPU")
else:
    print("Using CPU")

def create_cnn_model(input_shape, num_classes):
    model = models.Sequential()

    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))
    model.add(layers.MaxPooling2D((2, 2)))

    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))

    model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))

    model.add(layers.Flatten())

    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dense(num_classes, activation='softmax'))
    return model

input_shape = (224, 224, 3)
num_classes = len(train_gen_new.class_indices)

cnn_model = create_cnn_model(input_shape, num_classes)

cnn_model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

cnn_model.name = "CervicalCancerCNN"
print(cnn_model.name)  # Output: CervicalCancerCNN

cnn_model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = cnn_model.fit(
    train_gen_new,
    validation_data=valid_gen_new,
    epochs=100,
    verbose=1
)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

test_labels = test_gen_new.classes
predictions = cnn_model.predict(test_gen_new)
predicted_classes = np.argmax(predictions, axis=1)

from sklearn.metrics import classification_report

report = classification_report(test_labels, predicted_classes, target_names=list(test_gen_new.class_indices.keys()))
print(report)

conf_matrix = confusion_matrix(test_labels, predicted_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=list(test_gen_new.class_indices.keys()), yticklabels=list(test_gen_new.class_indices.keys()))
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

from tensorflow.keras.applications import InceptionV3

def create_inception_model(input_shape):

    base_model = InceptionV3(weights='imagenet', input_shape=input_shape, include_top=False)


    for layer in base_model.layers:
        layer.trainable = False

    model = Sequential()
    model.add(base_model)

    model.add(GaussianNoise(0.25))

    model.add(GlobalAveragePooling2D())

    model.add(Dense(512, activation='relu'))
    model.add(BatchNormalization())
    model.add(GaussianNoise(0.25))
    model.add(Dropout(0.25))

    model.add(Dense(5, activation='softmax'))

    return model

from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, GaussianNoise

input_shape = (224, 224, 3)
cnn_model = create_inception_model(input_shape)

cnn_model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

history = cnn_model.fit(
    train_gen_new,
    validation_data=valid_gen_new,
    epochs=40,
    verbose=1
)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

test_labels = test_gen_new.classes
predictions = cnn_model.predict(test_gen_new)
predicted_classes = np.argmax(predictions, axis=1)

from sklearn.metrics import classification_report

report = classification_report(test_labels, predicted_classes, target_names=list(test_gen_new.class_indices.keys()))
print(report)

conf_matrix = confusion_matrix(test_labels, predicted_classes)

plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=list(test_gen_new.class_indices.keys()), yticklabels=list(test_gen_new.class_indices.keys()))
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Data for CNN and Inception models
data = {
    'Category': [
        'im_Dyskeratotic',
        'im_Koilocytotic',
        'im_Metaplastic',
        'im_Parabasal',
        'im_Superficial-Intermediate'
    ],

    'Precision_CNN': [0.94, 0.85, 0.88, 0.98, 0.90],
    'Recall_CNN': [0.96, 0.83, 0.93, 0.95, 0.87],
    'F1_CNN': [0.95, 0.84, 0.90, 0.96, 0.88],

    'Precision_Inception': [0.94, 0.88, 0.87, 0.96, 0.88],
    'Recall_Inception': [0.96, 0.83, 0.92, 0.94, 0.89],
    'F1_Inception': [0.95, 0.86, 0.89, 0.95, 0.89],
}

df = pd.DataFrame(data)
df.set_index('Category', inplace=True)

fig, ax = plt.subplots(figsize=(12, 7))
bar_width = 0.12
x = np.arange(len(df.index))

metrics = ['Precision', 'Recall', 'F1']
colors = ['#1f77b4', '#ff7f0e', '#2ca02c']

# Plotting
for i, metric in enumerate(metrics):
    bars_cnn = ax.bar(x + i * bar_width, df[f'{metric}_CNN'], width=bar_width,
                      label=f'{metric} - CNN', color=colors[i])
    bars_inc = ax.bar(x + (i + len(metrics)) * bar_width, df[f'{metric}_Inception'], width=bar_width,
                      label=f'{metric} - Inception', color=colors[i], hatch='//')

    # Value labels
    for bar in list(bars_cnn) + list(bars_inc):
        height = bar.get_height()
        ax.annotate(f'{height:.2f}',
                    xy=(bar.get_x() + bar.get_width()/2, height),
                    ha='center', va='bottom', fontsize=8)

# Labels and Title
ax.set_xlabel('Categories', fontsize=13)
ax.set_ylabel('Score', fontsize=13)
ax.set_title('CNN vs Inception Model Comparison (Precision, Recall, F1-Score)', fontsize=15)

# X-ticks
ax.set_xticks(x + 1.5 * bar_width)
ax.set_xticklabels(df.index, rotation=15, fontsize=11)

# Legend below chart (moved more down)
ax.legend(title='Metrics', fontsize=10, loc='upper center', bbox_to_anchor=(0.5, -0.25),
          ncol=3, frameon=False)

# Layout adjustment
plt.tight_layout()
plt.subplots_adjust(bottom=0.3)
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Categories
categories = [
    'im_Dyskeratotic',
    'im_Koilocytotic',
    'im_Metaplastic',
    'im_Parabasal',
    'im_Superficial-Intermediate'
]

# Support values
support_cnn = [83, 83, 83, 84, 83]
support_inception = [83, 83, 83, 84, 83]

# Plot setup
x = np.arange(len(categories))
bar_width = 0.35

fig, ax = plt.subplots(figsize=(10, 6))

# Bars
bars1 = ax.bar(x - bar_width/2, support_cnn, width=bar_width, label='CNN', color='#1f77b4')
bars2 = ax.bar(x + bar_width/2, support_inception, width=bar_width, label='Inception', color='#ff7f0e', hatch='//')

# Value labels
for bar in list(bars1) + list(bars2):
    height = bar.get_height()
    ax.annotate(f'{height}', xy=(bar.get_x() + bar.get_width()/2, height + 0.5),
                ha='center', va='bottom', fontsize=10)

# Labels and title
ax.set_xlabel('Categories', fontsize=12)
ax.set_ylabel('Support Count', fontsize=12)
ax.set_title('Support Comparison: CNN vs Inception', fontsize=14)
ax.set_xticks(x)
ax.set_xticklabels(categories, rotation=15)
ax.legend()

plt.tight_layout()
plt.show()